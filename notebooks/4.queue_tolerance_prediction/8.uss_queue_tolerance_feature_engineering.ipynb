{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# USS Queue Tolerance Prediction - Feature & Label Engineering\n",
    "\n",
    "## Project Overview\n",
    "This notebook performs comprehensive feature engineering and label generation for predicting tourist queue tolerance at Universal Studios Singapore (USS). The focus is on wait time tolerance analysis using NLP-based approaches with minimal hardcoded keywords.\n",
    "\n",
    "**Main Tasks:**\n",
    "- Queue tolerance classification (3-class)\n",
    "- Wait time threshold regression\n",
    "- Wait experience satisfaction (4-level)\n",
    "- Time sensitivity classification (binary)\n",
    "\n",
    "**Features (32D):** Fine-grained sentiment (12D) + Temporal-spatial (5D) + Facility (8D) + User behavior (5D) + Time sensitivity (2D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!pip install vaderSentiment spacy pandas numpy scikit-learn -q\n",
    "!python -m spacy download en_core_web_sm -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted working directory to project root\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Ensure working from project root\n",
    "current_dir = os.getcwd()\n",
    "if current_dir.endswith('notebooks'):\n",
    "    os.chdir('..')\n",
    "    print(\"Adjusted working directory to project root\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "from collections import Counter\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import spacy\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading & Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded: (19224, 9)\n"
     ]
    }
   ],
   "source": [
    "# Load NLP models and configurations\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Load facility configurations\n",
    "with open('output/dashboard/config/FullList_normalized_v1.json', 'r') as f:\n",
    "    facility_config = json.load(f)\n",
    "with open('output/dashboard/config/others_normalized_v1.json', 'r') as f:\n",
    "    others_config = json.load(f)\n",
    "\n",
    "# Load review dataset\n",
    "data_path = 'data/processed/'\n",
    "csv_file = \"USS_Reviews_Silver_Facility_Labeled.csv\"\n",
    "df = pd.read_csv(os.path.join(data_path, csv_file))\n",
    "\n",
    "print(f\"Data loaded: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Facility configuration completed: 92 items\n"
     ]
    }
   ],
   "source": [
    "# Create facility thrill scores and popularity metrics\n",
    "def create_facility_scores():\n",
    "    # Thrill level scores based on research\n",
    "    rides_scores = {\n",
    "        \"battlestar galactica cylon\": 1.0, \"battlestar galactica human\": 0.9,\n",
    "        \"revenge of the mummy\": 0.95, \"transformers the ride the ultimate 3d battle\": 0.8,\n",
    "        \"jurassic park rapids adventure\": 0.7, \"canopy flyer\": 0.5, \"enchanted airways\": 0.5,\n",
    "        \"puss in boots giant journey\": 0.4, \"accelerator\": 0.4, \"magic potion spin\": 0.3,\n",
    "        \"dino soarin\": 0.2, \"sesame street spaghetti space chase\": 0.3, \"silly swirly\": 0.2,\n",
    "        \"buggie boogie\": 0.2, \"despicable me minion mayhem\": 0.4, \"treasure hunters\": 0.3,\n",
    "        \"sesame street goes bollywood\": 0.3\n",
    "    }\n",
    "    \n",
    "    shows_scores = {\n",
    "        \"waterworld\": 0.8, \"lights camera action\": 0.6, \"shrek 4 d adventure\": 0.4,\n",
    "        \"transformers voices of cybertron\": 0.3, \"hatched featuring dr rodney\": 0.1,\n",
    "        \"raptor encounter with blue\": 0.2, \"raptor encounter generations\": 0.2,\n",
    "        \"despicable me family portrait\": 0.1\n",
    "    }\n",
    "    \n",
    "    all_scores = {**rides_scores, **shows_scores}\n",
    "    \n",
    "    # Add default scores for remaining facilities\n",
    "    for zone, categories in facility_config.items():\n",
    "        for category, items in categories.items():\n",
    "            for item in items:\n",
    "                if item not in all_scores:\n",
    "                    all_scores[item] = 0.3 if category in ['rides', 'shows'] else 0.0\n",
    "    \n",
    "    for item in others_config:\n",
    "        all_scores[item] = 0.0\n",
    "    \n",
    "    return all_scores\n",
    "\n",
    "facility_thrill_scores = create_facility_scores()\n",
    "\n",
    "# Calculate facility popularity from dataset mentions\n",
    "def calculate_facility_popularity(df):\n",
    "    all_facilities = []\n",
    "    for _, row in df.iterrows():\n",
    "        try:\n",
    "            rides = eval(row['label_rides']) if pd.notna(row['label_rides']) else []\n",
    "            shows = eval(row['label_shows']) if pd.notna(row['label_shows']) else []\n",
    "            others = eval(row['label_other']) if pd.notna(row['label_other']) else []\n",
    "            all_facilities.extend(rides + shows + others)\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    facility_counts = Counter(all_facilities)\n",
    "    total_reviews = len(df)\n",
    "    return {facility: count / total_reviews for facility, count in facility_counts.items()}\n",
    "\n",
    "facility_popularity = calculate_facility_popularity(df)\n",
    "print(f\"Facility configuration completed: {len(facility_thrill_scores)} items\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed data: 5409 rows\n"
     ]
    }
   ],
   "source": [
    "# Extract temporal information using regex patterns\n",
    "def extract_temporal_info(integrated_review):\n",
    "    visit_time = None\n",
    "    wait_time = None\n",
    "    \n",
    "    visit_match = re.search(r'\\[VISIT_TIME: ([^\\]]+)\\]', integrated_review)\n",
    "    if visit_match:\n",
    "        visit_time = visit_match.group(1).strip()\n",
    "    \n",
    "    wait_match = re.search(r'\\[WAIT_TIME: ([^\\]]+)\\]', integrated_review)\n",
    "    if wait_match:\n",
    "        wait_time = wait_match.group(1).strip()\n",
    "    \n",
    "    return visit_time, wait_time\n",
    "\n",
    "# Apply temporal extraction and filter data\n",
    "df[['visit_time', 'wait_time']] = df['integrated_review'].apply(\n",
    "    lambda x: pd.Series(extract_temporal_info(x))\n",
    ")\n",
    "\n",
    "df_filtered = df.dropna(subset=['visit_time', 'wait_time']).copy()\n",
    "\n",
    "# Convert wait time strings to numeric values\n",
    "def convert_wait_time_numeric(wait_time_str):\n",
    "    if pd.isna(wait_time_str):\n",
    "        return 0\n",
    "    wait_time_str = str(wait_time_str).lower()\n",
    "    if 'no wait' in wait_time_str: return 0\n",
    "    elif 'up to 10 min' in wait_time_str: return 5\n",
    "    elif '1030 min' in wait_time_str: return 20\n",
    "    elif '3060 min' in wait_time_str: return 45\n",
    "    elif '1 hr' in wait_time_str: return 60\n",
    "    else: return 0\n",
    "\n",
    "df_filtered['wait_time_numeric'] = df_filtered['wait_time'].apply(convert_wait_time_numeric)\n",
    "print(f\"Preprocessed data: {df_filtered.shape[0]} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Engineering - Fine-grained Sentiment Analysis (12D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-grained sentiment features extracted (12D)\n"
     ]
    }
   ],
   "source": [
    "# Advanced sentiment analysis using spaCy NLP features\n",
    "def extract_fine_grained_sentiment_spacy(text):\n",
    "    \"\"\"Extract 12D sentiment features using spaCy linguistic analysis\"\"\"\n",
    "    overall_scores = analyzer.polarity_scores(text)\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    # 1-3: Wait Experience Sentiment using dependency parsing\n",
    "    wait_related_spans = []\n",
    "    time_entities = [ent for ent in doc.ents if ent.label_ in [\"TIME\", \"DURATION\", \"CARDINAL\"]]\n",
    "    \n",
    "    # Find sentences containing time expressions or queue-related dependencies\n",
    "    for sent in doc.sents:\n",
    "        # Check for time entities or queue-related tokens\n",
    "        has_time_ref = any(ent.start >= sent.start and ent.end <= sent.end for ent in time_entities)\n",
    "        has_queue_deps = any(token.lemma_ in ['wait', 'queue', 'line'] for token in sent)\n",
    "        \n",
    "        if has_time_ref or has_queue_deps:\n",
    "            wait_related_spans.append(sent.text)\n",
    "    \n",
    "    if wait_related_spans:\n",
    "        wait_text = ' '.join(wait_related_spans)\n",
    "        wait_sentiment = analyzer.polarity_scores(wait_text)\n",
    "        wait_queue_perception = wait_sentiment['compound']\n",
    "        wait_queue_management = wait_sentiment['pos'] - wait_sentiment['neg']\n",
    "        wait_environment = len(wait_related_spans) / len(list(doc.sents))  # Proportion of wait mentions\n",
    "    else:\n",
    "        wait_queue_perception = 0\n",
    "        wait_queue_management = 0\n",
    "        wait_environment = 0\n",
    "    \n",
    "    # 4-6: Facility Experience using semantic roles\n",
    "    attraction_spans = []\n",
    "    for sent in doc.sents:\n",
    "        # Look for entertainment/attraction related semantic patterns\n",
    "        for token in sent:\n",
    "            if (token.pos_ in ['NOUN', 'PROPN'] and \n",
    "                any(child.dep_ == 'amod' and child.lemma_ in ['fun', 'exciting', 'boring', 'great'] \n",
    "                    for child in token.children)):\n",
    "                attraction_spans.append(sent.text)\n",
    "                break\n",
    "    \n",
    "    if attraction_spans:\n",
    "        attraction_text = ' '.join(attraction_spans)\n",
    "        facility_sentiment = analyzer.polarity_scores(attraction_text)\n",
    "        facility_quality = facility_sentiment['compound']\n",
    "    else:\n",
    "        facility_quality = overall_scores['compound']\n",
    "    \n",
    "    # Technical issues using negative semantic patterns\n",
    "    technical_issues = 0\n",
    "    for token in doc:\n",
    "        if (token.lemma_ in ['close', 'break', 'maintenance'] and \n",
    "            any(child.dep_ == 'neg' for child in token.children)):\n",
    "            technical_issues -= 0.1\n",
    "    \n",
    "    # Safety perception using sentiment-bearing adjectives\n",
    "    safety_score = 0\n",
    "    for token in doc:\n",
    "        if token.pos_ == 'ADJ' and token.lemma_ in ['safe', 'secure']:\n",
    "            safety_score += 0.2\n",
    "        elif token.pos_ == 'ADJ' and token.lemma_ in ['dangerous', 'unsafe']:\n",
    "            safety_score -= 0.2\n",
    "    safety_perception = np.clip(safety_score, -1, 1)\n",
    "    \n",
    "    # 7-8: Service Quality using person entities and service verbs\n",
    "    service_spans = []\n",
    "    for sent in doc.sents:\n",
    "        # Look for staff/service related mentions\n",
    "        has_person_ref = any(ent.label_ == 'PERSON' for ent in doc.ents \n",
    "                           if ent.start >= sent.start and ent.end <= sent.end)\n",
    "        has_service_verb = any(token.lemma_ in ['help', 'serve', 'assist'] for token in sent)\n",
    "        \n",
    "        if has_person_ref or has_service_verb:\n",
    "            service_spans.append(sent.text)\n",
    "    \n",
    "    if service_spans:\n",
    "        service_text = ' '.join(service_spans)\n",
    "        service_sentiment = analyzer.polarity_scores(service_text)\n",
    "        staff_attitude = service_sentiment['compound']\n",
    "        customer_service = service_sentiment['pos'] - service_sentiment['neg']\n",
    "    else:\n",
    "        staff_attitude = 0\n",
    "        customer_service = 0\n",
    "    \n",
    "    # 9-10: Price Perception using money entities and value expressions\n",
    "    price_spans = []\n",
    "    money_entities = [ent for ent in doc.ents if ent.label_ == 'MONEY']\n",
    "    \n",
    "    for sent in doc.sents:\n",
    "        has_money_ref = any(ent.start >= sent.start and ent.end <= sent.end for ent in money_entities)\n",
    "        has_value_term = any(token.lemma_ in ['price', 'cost', 'value', 'worth', 'expensive'] \n",
    "                            for token in sent)\n",
    "        \n",
    "        if has_money_ref or has_value_term:\n",
    "            price_spans.append(sent.text)\n",
    "    \n",
    "    if price_spans:\n",
    "        price_text = ' '.join(price_spans)\n",
    "        price_sentiment = analyzer.polarity_scores(price_text)\n",
    "        express_value = price_sentiment['compound'] if 'express' in price_text.lower() else 0\n",
    "        overall_value = price_sentiment['pos'] - price_sentiment['neg']\n",
    "    else:\n",
    "        express_value = 0\n",
    "        overall_value = 0\n",
    "    \n",
    "    # 11-12: Overall Satisfaction using semantic patterns\n",
    "    recommend_score = 0\n",
    "    for token in doc:\n",
    "        if token.lemma_ in ['recommend', 'suggest'] and token.dep_ == 'ROOT':\n",
    "            recommend_score += 0.3\n",
    "        elif token.lemma_ in ['return', 'again'] and any(child.lemma_ == 'would' for child in token.children):\n",
    "            recommend_score += 0.2\n",
    "    \n",
    "    overall_satisfaction = overall_scores['compound']\n",
    "    \n",
    "    return [\n",
    "        wait_queue_perception, wait_queue_management, wait_environment,\n",
    "        facility_quality, technical_issues, safety_perception,\n",
    "        staff_attitude, customer_service,\n",
    "        express_value, overall_value,\n",
    "        recommend_score, overall_satisfaction\n",
    "    ]\n",
    "\n",
    "# Apply advanced sentiment analysis\n",
    "sentiment_features = df_filtered['review'].apply(extract_fine_grained_sentiment_spacy)\n",
    "sentiment_df = pd.DataFrame(\n",
    "    sentiment_features.tolist(),\n",
    "    columns=[\n",
    "        'wait_queue_perception', 'wait_queue_management', 'wait_environment',\n",
    "        'facility_quality', 'technical_issues', 'safety_perception',\n",
    "        'staff_attitude', 'customer_service',\n",
    "        'express_value', 'overall_value',\n",
    "        'recommend_score', 'overall_satisfaction'\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"Fine-grained sentiment features extracted (12D)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wait_queue_perception</th>\n",
       "      <th>wait_queue_management</th>\n",
       "      <th>wait_environment</th>\n",
       "      <th>facility_quality</th>\n",
       "      <th>technical_issues</th>\n",
       "      <th>safety_perception</th>\n",
       "      <th>staff_attitude</th>\n",
       "      <th>customer_service</th>\n",
       "      <th>express_value</th>\n",
       "      <th>overall_value</th>\n",
       "      <th>recommend_score</th>\n",
       "      <th>overall_satisfaction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5409.000000</td>\n",
       "      <td>5409.000000</td>\n",
       "      <td>5409.000000</td>\n",
       "      <td>5409.000000</td>\n",
       "      <td>5409.000000</td>\n",
       "      <td>5409.000000</td>\n",
       "      <td>5409.000000</td>\n",
       "      <td>5409.000000</td>\n",
       "      <td>5409.000000</td>\n",
       "      <td>5409.000000</td>\n",
       "      <td>5409.000000</td>\n",
       "      <td>5409.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.138950</td>\n",
       "      <td>0.039444</td>\n",
       "      <td>0.254061</td>\n",
       "      <td>0.515927</td>\n",
       "      <td>-0.000074</td>\n",
       "      <td>0.001035</td>\n",
       "      <td>0.065949</td>\n",
       "      <td>0.025947</td>\n",
       "      <td>0.010243</td>\n",
       "      <td>0.024823</td>\n",
       "      <td>0.038491</td>\n",
       "      <td>0.527108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.352155</td>\n",
       "      <td>0.110499</td>\n",
       "      <td>0.298179</td>\n",
       "      <td>0.476243</td>\n",
       "      <td>0.002719</td>\n",
       "      <td>0.020326</td>\n",
       "      <td>0.243168</td>\n",
       "      <td>0.103063</td>\n",
       "      <td>0.093706</td>\n",
       "      <td>0.104304</td>\n",
       "      <td>0.114295</td>\n",
       "      <td>0.488991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-0.969200</td>\n",
       "      <td>-0.756000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.988800</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>-0.200000</td>\n",
       "      <td>-0.936100</td>\n",
       "      <td>-0.610000</td>\n",
       "      <td>-0.953900</td>\n",
       "      <td>-0.615000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.988800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.329100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.325700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.675700</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.709900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.361200</td>\n",
       "      <td>0.069000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.870300</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.895700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.992500</td>\n",
       "      <td>0.726000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.989600</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.967600</td>\n",
       "      <td>0.839000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>0.999700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       wait_queue_perception  wait_queue_management  wait_environment  \\\n",
       "count            5409.000000            5409.000000       5409.000000   \n",
       "mean                0.138950               0.039444          0.254061   \n",
       "std                 0.352155               0.110499          0.298179   \n",
       "min                -0.969200              -0.756000          0.000000   \n",
       "25%                 0.000000               0.000000          0.000000   \n",
       "50%                 0.000000               0.000000          0.181818   \n",
       "75%                 0.361200               0.069000          0.428571   \n",
       "max                 0.992500               0.726000          1.000000   \n",
       "\n",
       "       facility_quality  technical_issues  safety_perception  staff_attitude  \\\n",
       "count       5409.000000       5409.000000        5409.000000     5409.000000   \n",
       "mean           0.515927         -0.000074           0.001035        0.065949   \n",
       "std            0.476243          0.002719           0.020326        0.243168   \n",
       "min           -0.988800         -0.100000          -0.200000       -0.936100   \n",
       "25%            0.329100          0.000000           0.000000        0.000000   \n",
       "50%            0.675700          0.000000           0.000000        0.000000   \n",
       "75%            0.870300          0.000000           0.000000        0.000000   \n",
       "max            0.999200          0.000000           0.600000        0.989600   \n",
       "\n",
       "       customer_service  express_value  overall_value  recommend_score  \\\n",
       "count       5409.000000    5409.000000    5409.000000      5409.000000   \n",
       "mean           0.025947       0.010243       0.024823         0.038491   \n",
       "std            0.103063       0.093706       0.104304         0.114295   \n",
       "min           -0.610000      -0.953900      -0.615000         0.000000   \n",
       "25%            0.000000       0.000000       0.000000         0.000000   \n",
       "50%            0.000000       0.000000       0.000000         0.000000   \n",
       "75%            0.000000       0.000000       0.000000         0.000000   \n",
       "max            1.000000       0.967600       0.839000         1.800000   \n",
       "\n",
       "       overall_satisfaction  \n",
       "count           5409.000000  \n",
       "mean               0.527108  \n",
       "std                0.488991  \n",
       "min               -0.988800  \n",
       "25%                0.325700  \n",
       "50%                0.709900  \n",
       "75%                0.895700  \n",
       "max                0.999700  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Feature Engineering - Temporal-Spatial Context (5D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temporal-spatial features extracted (5D)\n"
     ]
    }
   ],
   "source": [
    "# Extract temporal-spatial context features\n",
    "def extract_temporal_spatial_features(row):\n",
    "    # Visit time one-hot encoding\n",
    "    visit_time = row['visit_time']\n",
    "    weekday = 1 if visit_time == 'Weekday' else 0\n",
    "    weekend = 1 if visit_time == 'Weekend' else 0\n",
    "    holiday = 1 if visit_time == 'Public holiday' else 0\n",
    "    \n",
    "    # Numeric wait time\n",
    "    wait_time_numeric = row['wait_time_numeric']\n",
    "    \n",
    "    # Season factor based on Singapore climate patterns\n",
    "    try:\n",
    "        date_obj = pd.to_datetime(row['publishedAtDate'], format='%m/%d/%y')\n",
    "        month = date_obj.month\n",
    "        # Peak season: Dec-Feb (holidays), Jun-Aug (summer)\n",
    "        season_factor = 1.0 if month in [12, 1, 2, 6, 7, 8] else 0.5\n",
    "    except:\n",
    "        season_factor = 0.75\n",
    "    \n",
    "    return [weekday, weekend, holiday, wait_time_numeric, season_factor]\n",
    "\n",
    "temporal_features = df_filtered.apply(extract_temporal_spatial_features, axis=1)\n",
    "temporal_df = pd.DataFrame(\n",
    "    temporal_features.tolist(),\n",
    "    columns=['weekday', 'weekend', 'holiday', 'wait_time_numeric', 'season_factor']\n",
    ")\n",
    "\n",
    "print(\"Temporal-spatial features extracted (5D)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weekday</th>\n",
       "      <th>weekend</th>\n",
       "      <th>holiday</th>\n",
       "      <th>wait_time_numeric</th>\n",
       "      <th>season_factor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5409.000000</td>\n",
       "      <td>5409.000000</td>\n",
       "      <td>5409.000000</td>\n",
       "      <td>5409.000000</td>\n",
       "      <td>5409.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.667221</td>\n",
       "      <td>0.270845</td>\n",
       "      <td>0.061934</td>\n",
       "      <td>17.542984</td>\n",
       "      <td>0.746534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.471252</td>\n",
       "      <td>0.444437</td>\n",
       "      <td>0.241058</td>\n",
       "      <td>21.431294</td>\n",
       "      <td>0.249999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           weekday      weekend      holiday  wait_time_numeric  season_factor\n",
       "count  5409.000000  5409.000000  5409.000000        5409.000000    5409.000000\n",
       "mean      0.667221     0.270845     0.061934          17.542984       0.746534\n",
       "std       0.471252     0.444437     0.241058          21.431294       0.249999\n",
       "min       0.000000     0.000000     0.000000           0.000000       0.500000\n",
       "25%       0.000000     0.000000     0.000000           0.000000       0.500000\n",
       "50%       1.000000     0.000000     0.000000           5.000000       0.500000\n",
       "75%       1.000000     1.000000     0.000000          20.000000       1.000000\n",
       "max       1.000000     1.000000     1.000000          60.000000       1.000000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temporal_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Feature Engineering - Facility Characteristics (8D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Facility features extracted (8D)\n"
     ]
    }
   ],
   "source": [
    "# Extract facility-related features\n",
    "def extract_facility_features(row):\n",
    "    try:\n",
    "        rides = eval(row['label_rides']) if pd.notna(row['label_rides']) else []\n",
    "        shows = eval(row['label_shows']) if pd.notna(row['label_shows']) else []\n",
    "        others = eval(row['label_other']) if pd.notna(row['label_other']) else []\n",
    "    except:\n",
    "        rides, shows, others = [], [], []\n",
    "    \n",
    "    # Basic facility counts\n",
    "    rides_count = len(rides)\n",
    "    shows_count = len(shows)\n",
    "    other_count = len(others)\n",
    "    \n",
    "    # Thrill level calculations\n",
    "    all_facilities = rides + shows + others\n",
    "    thrill_scores = [facility_thrill_scores.get(facility, 0) for facility in all_facilities]\n",
    "    \n",
    "    avg_thrill_level = np.mean(thrill_scores) if thrill_scores else 0\n",
    "    max_thrill_level = max(thrill_scores) if thrill_scores else 0\n",
    "    \n",
    "    # Facility diversity score\n",
    "    facility_types = sum([rides_count > 0, shows_count > 0, other_count > 0])\n",
    "    facility_diversity = facility_types / 3\n",
    "    \n",
    "    # Express pass usage indicator\n",
    "    express_usage = 1 if 'express' in others else 0\n",
    "    \n",
    "    # Main facility popularity score\n",
    "    popularities = [facility_popularity.get(facility, 0) for facility in all_facilities]\n",
    "    main_facility_popularity = max(popularities) if popularities else 0\n",
    "    \n",
    "    return [\n",
    "        rides_count, shows_count, other_count,\n",
    "        avg_thrill_level, max_thrill_level,\n",
    "        facility_diversity, express_usage, main_facility_popularity\n",
    "    ]\n",
    "\n",
    "facility_features = df_filtered.apply(extract_facility_features, axis=1)\n",
    "facility_df = pd.DataFrame(\n",
    "    facility_features.tolist(),\n",
    "    columns=[\n",
    "        'rides_count', 'shows_count', 'other_count',\n",
    "        'avg_thrill_level', 'max_thrill_level',\n",
    "        'facility_diversity', 'express_usage', 'main_facility_popularity'\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"Facility features extracted (8D)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rides_count</th>\n",
       "      <th>shows_count</th>\n",
       "      <th>other_count</th>\n",
       "      <th>avg_thrill_level</th>\n",
       "      <th>max_thrill_level</th>\n",
       "      <th>facility_diversity</th>\n",
       "      <th>express_usage</th>\n",
       "      <th>main_facility_popularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5409.000000</td>\n",
       "      <td>5409.000000</td>\n",
       "      <td>5409.000000</td>\n",
       "      <td>5409.000000</td>\n",
       "      <td>5409.000000</td>\n",
       "      <td>5409.000000</td>\n",
       "      <td>5409.000000</td>\n",
       "      <td>5409.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.599187</td>\n",
       "      <td>0.691440</td>\n",
       "      <td>1.527639</td>\n",
       "      <td>0.198509</td>\n",
       "      <td>0.361675</td>\n",
       "      <td>0.544155</td>\n",
       "      <td>0.264929</td>\n",
       "      <td>0.178051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.169212</td>\n",
       "      <td>0.874103</td>\n",
       "      <td>1.415659</td>\n",
       "      <td>0.221670</td>\n",
       "      <td>0.357940</td>\n",
       "      <td>0.244740</td>\n",
       "      <td>0.441336</td>\n",
       "      <td>0.083959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.183885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.269143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.269143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       rides_count  shows_count  other_count  avg_thrill_level  \\\n",
       "count  5409.000000  5409.000000  5409.000000       5409.000000   \n",
       "mean      0.599187     0.691440     1.527639          0.198509   \n",
       "std       1.169212     0.874103     1.415659          0.221670   \n",
       "min       0.000000     0.000000     0.000000          0.000000   \n",
       "25%       0.000000     0.000000     1.000000          0.000000   \n",
       "50%       0.000000     1.000000     1.000000          0.150000   \n",
       "75%       1.000000     1.000000     2.000000          0.300000   \n",
       "max      10.000000     9.000000    12.000000          1.000000   \n",
       "\n",
       "       max_thrill_level  facility_diversity  express_usage  \\\n",
       "count       5409.000000         5409.000000    5409.000000   \n",
       "mean           0.361675            0.544155       0.264929   \n",
       "std            0.357940            0.244740       0.441336   \n",
       "min            0.000000            0.333333       0.000000   \n",
       "25%            0.000000            0.333333       0.000000   \n",
       "50%            0.300000            0.333333       0.000000   \n",
       "75%            0.700000            0.666667       1.000000   \n",
       "max            1.000000            1.000000       1.000000   \n",
       "\n",
       "       main_facility_popularity  \n",
       "count               5409.000000  \n",
       "mean                   0.178051  \n",
       "std                    0.083959  \n",
       "min                    0.000052  \n",
       "25%                    0.111527  \n",
       "50%                    0.183885  \n",
       "75%                    0.269143  \n",
       "max                    0.269143  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "facility_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Feature Engineering - User Behavior Analysis (5D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User behavior features extracted (5D)\n"
     ]
    }
   ],
   "source": [
    "# Extract user behavior features using spaCy linguistic analysis\n",
    "def extract_user_behavior_features_spacy(text):\n",
    "    \"\"\"Extract user behavior patterns using advanced NLP analysis\"\"\"\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    # 1. Review complexity (normalized length)\n",
    "    review_length_norm = min(len(text) / 500, 1.0)\n",
    "    \n",
    "    # 2. Detailed facility engagement using entity recognition\n",
    "    facility_entity_mentions = 0\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ in ['ORG', 'PRODUCT', 'EVENT'] or ent.text.lower() in facility_thrill_scores:\n",
    "            facility_entity_mentions += 1\n",
    "    detailed_mention = min(facility_entity_mentions / 3, 1.0)\n",
    "    \n",
    "    # 3. Complaint intensity using linguistic features\n",
    "    exclamation_count = text.count('!')\n",
    "    caps_ratio = sum(1 for c in text if c.isupper()) / len(text) if text else 0\n",
    "    \n",
    "    # Analyze negation patterns and emotional intensity\n",
    "    negative_modifiers = 0\n",
    "    for token in doc:\n",
    "        if token.dep_ == 'neg' or token.lemma_ in ['not', 'never', 'no']:\n",
    "            negative_modifiers += 1\n",
    "        elif token.pos_ == 'ADV' and any(child.pos_ == 'ADJ' for child in token.children):\n",
    "            if token.lemma_ in ['very', 'extremely', 'really']:\n",
    "                negative_modifiers += 0.5\n",
    "    \n",
    "    complaint_intensity = min(\n",
    "        (exclamation_count / 5 + caps_ratio * 3 + negative_modifiers / len(doc)) / 3,\n",
    "        1.0\n",
    "    )\n",
    "    \n",
    "    # 4. Positive sentiment ratio from VADER\n",
    "    sentiment_scores = analyzer.polarity_scores(text)\n",
    "    positive_sentiment_ratio = sentiment_scores['pos']\n",
    "    \n",
    "    # 5. Group interaction patterns using dependency parsing\n",
    "    personal_pronouns = [token.text.lower() for token in doc if token.pos_ == \"PRON\"]\n",
    "    we_us_count = sum(1 for p in personal_pronouns if p in ['we', 'us', 'our'])\n",
    "    i_me_count = sum(1 for p in personal_pronouns if p in ['i', 'me', 'my'])\n",
    "    \n",
    "    # Detect family/group indicators using named entities and semantic patterns\n",
    "    group_indicators = 0\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == 'PERSON' and len(ent.text.split()) > 1:  # Multiple names\n",
    "            group_indicators += 1\n",
    "    \n",
    "    for token in doc:\n",
    "        if token.lemma_ in ['family', 'friend', 'kid', 'child', 'together', 'group']:\n",
    "            group_indicators += 1\n",
    "    \n",
    "    # Calculate group interaction score\n",
    "    if we_us_count > i_me_count and group_indicators > 0:\n",
    "        group_interaction_indicator = 1.0\n",
    "    elif we_us_count > 0 or group_indicators > 0:\n",
    "        group_interaction_indicator = 0.5\n",
    "    else:\n",
    "        group_interaction_indicator = 0.0\n",
    "    \n",
    "    return [\n",
    "        review_length_norm, detailed_mention, complaint_intensity,\n",
    "        positive_sentiment_ratio, group_interaction_indicator\n",
    "    ]\n",
    "\n",
    "user_features = df_filtered['review'].apply(extract_user_behavior_features_spacy)\n",
    "user_df = pd.DataFrame(\n",
    "    user_features.tolist(),\n",
    "    columns=[\n",
    "        'review_length_norm', 'detailed_mention', 'complaint_intensity',\n",
    "        'positive_sentiment_ratio', 'group_interaction_indicator'\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(\"User behavior features extracted (5D)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_length_norm</th>\n",
       "      <th>detailed_mention</th>\n",
       "      <th>complaint_intensity</th>\n",
       "      <th>positive_sentiment_ratio</th>\n",
       "      <th>group_interaction_indicator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5409.000000</td>\n",
       "      <td>5409.000000</td>\n",
       "      <td>5409.000000</td>\n",
       "      <td>5409.000000</td>\n",
       "      <td>5409.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.480635</td>\n",
       "      <td>0.169656</td>\n",
       "      <td>0.060851</td>\n",
       "      <td>0.202715</td>\n",
       "      <td>0.219264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.325590</td>\n",
       "      <td>0.289308</td>\n",
       "      <td>0.086207</td>\n",
       "      <td>0.147405</td>\n",
       "      <td>0.286678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.198000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021978</td>\n",
       "      <td>0.099000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.382000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032609</td>\n",
       "      <td>0.179000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.774000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.059091</td>\n",
       "      <td>0.281000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       review_length_norm  detailed_mention  complaint_intensity  \\\n",
       "count         5409.000000       5409.000000          5409.000000   \n",
       "mean             0.480635          0.169656             0.060851   \n",
       "std              0.325590          0.289308             0.086207   \n",
       "min              0.020000          0.000000             0.000000   \n",
       "25%              0.198000          0.000000             0.021978   \n",
       "50%              0.382000          0.000000             0.032609   \n",
       "75%              0.774000          0.333333             0.059091   \n",
       "max              1.000000          1.000000             1.000000   \n",
       "\n",
       "       positive_sentiment_ratio  group_interaction_indicator  \n",
       "count               5409.000000                  5409.000000  \n",
       "mean                   0.202715                     0.219264  \n",
       "std                    0.147405                     0.286678  \n",
       "min                    0.000000                     0.000000  \n",
       "25%                    0.099000                     0.000000  \n",
       "50%                    0.179000                     0.000000  \n",
       "75%                    0.281000                     0.500000  \n",
       "max                    1.000000                     1.000000  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Feature Engineering - Time Sensitivity Indicators (2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time sensitivity features extracted (2D)\n"
     ]
    }
   ],
   "source": [
    "# Extract time sensitivity features\n",
    "def extract_time_sensitivity_features(row):\n",
    "    # Holiday pressure factor (increased sensitivity during holidays)\n",
    "    if row['visit_time'] == 'Public holiday':\n",
    "        holiday_pressure_factor = row['wait_time_numeric'] / 60\n",
    "    else:\n",
    "        holiday_pressure_factor = 0\n",
    "    \n",
    "    # Seasonal mood adjustment (peak season amplifies wait time impact)\n",
    "    season_factor = row['season_factor']\n",
    "    wait_time_norm = row['wait_time_numeric'] / 60\n",
    "    seasonal_mood_adjustment = season_factor * wait_time_norm\n",
    "    \n",
    "    return [holiday_pressure_factor, seasonal_mood_adjustment]\n",
    "\n",
    "# Combine data for time sensitivity calculation\n",
    "temp_combined = pd.concat([\n",
    "    df_filtered[['visit_time', 'wait_time_numeric']].reset_index(drop=True), \n",
    "    temporal_df[['season_factor']].reset_index(drop=True)\n",
    "], axis=1)\n",
    "\n",
    "time_sensitivity_features = temp_combined.apply(extract_time_sensitivity_features, axis=1)\n",
    "time_sensitivity_df = pd.DataFrame(\n",
    "    time_sensitivity_features.tolist(),\n",
    "    columns=['holiday_pressure_factor', 'seasonal_mood_adjustment']\n",
    ")\n",
    "\n",
    "print(\"Time sensitivity features extracted (2D)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>holiday_pressure_factor</th>\n",
       "      <th>seasonal_mood_adjustment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5409.000000</td>\n",
       "      <td>5409.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.023248</td>\n",
       "      <td>0.226559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.130764</td>\n",
       "      <td>0.304287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       holiday_pressure_factor  seasonal_mood_adjustment\n",
       "count              5409.000000               5409.000000\n",
       "mean                  0.023248                  0.226559\n",
       "std                   0.130764                  0.304287\n",
       "min                   0.000000                  0.000000\n",
       "25%                   0.000000                  0.000000\n",
       "50%                   0.000000                  0.083333\n",
       "75%                   0.000000                  0.333333\n",
       "max                   1.000000                  1.000000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_sensitivity_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Label Engineering - Queue Tolerance Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All labels generated successfully\n"
     ]
    }
   ],
   "source": [
    "# Generate queue tolerance classification labels\n",
    "def generate_tolerance_labels_advanced(row):\n",
    "    \"\"\"Generate tolerance labels using layered decision tree with 100% coverage\"\"\"\n",
    "    doc = nlp(row['review'])\n",
    "    \n",
    "    # Extract basic metrics\n",
    "    stars = row['stars']\n",
    "    wait_time = row['wait_time_numeric']\n",
    "    overall_sentiment = analyzer.polarity_scores(row['review'])['compound']\n",
    "    \n",
    "    # Extract wait-related sentiment for middle/long wait analysis\n",
    "    wait_related_spans = []\n",
    "    time_entities = [ent for ent in doc.ents if ent.label_ in [\"TIME\", \"DURATION\", \"CARDINAL\"]]\n",
    "    \n",
    "    for sent in doc.sents:\n",
    "        has_time_ref = any(ent.start >= sent.start and ent.end <= sent.end for ent in time_entities)\n",
    "        has_wait_verb = any(token.lemma_ in ['wait', 'queue', 'line'] for token in sent)\n",
    "        \n",
    "        if has_time_ref or has_wait_verb:\n",
    "            wait_related_spans.append(sent.text)\n",
    "    \n",
    "    if wait_related_spans:\n",
    "        wait_text = ' '.join(wait_related_spans)\n",
    "        wait_sentiment = analyzer.polarity_scores(wait_text)['compound']\n",
    "    else:\n",
    "        wait_sentiment = overall_sentiment\n",
    "    \n",
    "    # Layer 1: Wait time grouping with Layer 2: Stars + sentiment classification\n",
    "    if wait_time == 0:\n",
    "        # No wait scenario - based on overall satisfaction potential\n",
    "        if stars >= 4:\n",
    "            return 'high_tolerance'  # High satisfaction suggests tolerance for future waits\n",
    "        elif stars == 3:\n",
    "            return 'critical_tolerance'  # Neutral satisfaction at baseline\n",
    "        else:\n",
    "            return 'tolerance_collapse'  # Low satisfaction even without wait\n",
    "            \n",
    "    elif 1 <= wait_time <= 15:\n",
    "        # Short wait scenario - direct satisfaction mapping\n",
    "        if stars >= 4:\n",
    "            return 'high_tolerance'  # Satisfied with short wait\n",
    "        elif stars == 3:\n",
    "            return 'critical_tolerance'  # Acceptable short wait experience\n",
    "        else:\n",
    "            return 'tolerance_collapse'  # Dissatisfied even with short wait\n",
    "            \n",
    "    elif 16 <= wait_time <= 45:\n",
    "        # Medium wait scenario - sentiment becomes important\n",
    "        if stars >= 4 and wait_sentiment >= 0.0:\n",
    "            return 'high_tolerance'  # High stars + positive/neutral wait sentiment\n",
    "        elif stars == 3 or (stars >= 4 and wait_sentiment < 0.0):\n",
    "            return 'critical_tolerance'  # Neutral stars OR high stars with negative wait sentiment\n",
    "        else:\n",
    "            return 'tolerance_collapse'  # Low satisfaction with medium wait\n",
    "            \n",
    "    else:  # wait_time > 45\n",
    "        # Long wait scenario - stricter criteria for high tolerance\n",
    "        if stars == 5 and wait_sentiment >= 0.0:\n",
    "            return 'high_tolerance'  # Perfect rating with positive wait experience\n",
    "        elif stars >= 3:\n",
    "            return 'critical_tolerance'  # Acceptable rating despite long wait\n",
    "        else:\n",
    "            return 'tolerance_collapse'  # Poor rating with long wait\n",
    "\n",
    "# Generate wait time threshold regression labels\n",
    "def generate_wait_threshold_labels(row):\n",
    "    \"\"\"Generate wait time threshold labels using psychological model with multi-factor adjustment\"\"\"\n",
    "    stars = row['stars']\n",
    "    wait_time = row['wait_time_numeric']\n",
    "    visit_time = row['visit_time']\n",
    "    overall_sentiment = analyzer.polarity_scores(row['review'])['compound']\n",
    "    \n",
    "    # Extract facility information for thrill level calculation\n",
    "    try:\n",
    "        rides = eval(row['label_rides']) if pd.notna(row['label_rides']) else []\n",
    "        shows = eval(row['label_shows']) if pd.notna(row['label_shows']) else []\n",
    "        others = eval(row['label_other']) if pd.notna(row['label_other']) else []\n",
    "        all_facilities = rides + shows + others\n",
    "    except:\n",
    "        all_facilities = []\n",
    "    \n",
    "    # Calculate average thrill level for visited facilities\n",
    "    if all_facilities:\n",
    "        thrill_scores = [facility_thrill_scores.get(facility, 0.3) for facility in all_facilities]\n",
    "        avg_thrill_level = np.mean(thrill_scores)\n",
    "    else:\n",
    "        avg_thrill_level = 0.3  # Default moderate thrill level\n",
    "    \n",
    "    # Base threshold calculation based on facility thrill level\n",
    "    if avg_thrill_level >= 0.7:\n",
    "        base_threshold = 45  # High thrill facilities warrant longer waits\n",
    "    elif avg_thrill_level >= 0.4:\n",
    "        base_threshold = 30  # Medium thrill facilities\n",
    "    else:\n",
    "        base_threshold = 20  # Low thrill facilities and services\n",
    "    \n",
    "    # Personal adjustment factor based on satisfaction indicators\n",
    "    satisfaction_factor_map = {5: 1.5, 4: 1.2, 3: 1.0, 2: 0.8, 1: 0.6}\n",
    "    personal_factor = satisfaction_factor_map.get(stars, 1.0)\n",
    "    \n",
    "    # Sentiment adjustment within personal factor\n",
    "    if overall_sentiment >= 0.3:\n",
    "        personal_factor *= 1.1  # Boost for very positive sentiment\n",
    "    elif overall_sentiment <= -0.3:\n",
    "        personal_factor *= 0.9  # Penalty for negative sentiment\n",
    "    \n",
    "    # Group interaction adjustment based on review patterns\n",
    "    review_text = row['review'].lower()\n",
    "    group_indicators = ['family', 'friend', 'kid', 'child', 'together', 'we', 'us', 'our']\n",
    "    individual_indicators = ['i ', 'my ', 'me ']\n",
    "    \n",
    "    group_score = sum(1 for indicator in group_indicators if indicator in review_text)\n",
    "    individual_score = sum(1 for indicator in individual_indicators if indicator in review_text)\n",
    "    \n",
    "    if group_score > individual_score and group_score >= 2:\n",
    "        group_factor = 0.8  # Families/groups less tolerant due to coordination complexity\n",
    "    elif individual_score > group_score:\n",
    "        group_factor = 1.0  # Individual baseline\n",
    "    else:\n",
    "        group_factor = 1.2  # Friend groups more tolerant and flexible\n",
    "    \n",
    "    # Temporal adjustment factor based on visit timing\n",
    "    temporal_factor_map = {\n",
    "        'Weekday': 1.2,     # More tolerant during weekdays (less crowded)\n",
    "        'Weekend': 1.0,     # Baseline weekend expectations\n",
    "        'Public holiday': 0.8  # Less tolerant during holidays (higher stress)\n",
    "    }\n",
    "    temporal_factor = temporal_factor_map.get(visit_time, 1.0)\n",
    "    \n",
    "    # Calculate final threshold using psychological model\n",
    "    calculated_threshold = base_threshold * personal_factor * group_factor * temporal_factor\n",
    "    \n",
    "    # Actual wait time consideration for threshold adjustment\n",
    "    if wait_time > 0:\n",
    "        # If user waited X minutes and gave rating Y, adjust threshold accordingly\n",
    "        if stars >= 4:\n",
    "            # High satisfaction suggests tolerance above actual wait time\n",
    "            experience_threshold = wait_time + 10\n",
    "        elif stars <= 2:\n",
    "            # Low satisfaction suggests threshold below actual wait time\n",
    "            experience_threshold = max(wait_time - 10, 5)\n",
    "        else:\n",
    "            # Neutral satisfaction suggests actual wait time approximates threshold\n",
    "            experience_threshold = wait_time\n",
    "        \n",
    "        # Take maximum of calculated and experience-based thresholds\n",
    "        final_threshold = max(calculated_threshold, experience_threshold)\n",
    "    else:\n",
    "        final_threshold = calculated_threshold\n",
    "    \n",
    "    # Ensure threshold stays within reasonable bounds\n",
    "    return max(min(final_threshold, 120), 5)  # Clamp between 5-120 minutes\n",
    "\n",
    "# Generate wait experience satisfaction labels\n",
    "def generate_wait_experience_satisfaction(row):\n",
    "    \"\"\"Generate wait experience satisfaction labels for all reviews\"\"\"\n",
    "    stars = row['stars']\n",
    "    wait_time = row['wait_time_numeric']\n",
    "    overall_sentiment = analyzer.polarity_scores(row['review'])['compound']\n",
    "    \n",
    "    # Combined satisfaction score considering wait time impact\n",
    "    wait_penalty = wait_time / 60 * 0.2  # Penalty increases with wait time\n",
    "    adjusted_satisfaction = overall_sentiment - wait_penalty\n",
    "    \n",
    "    if adjusted_satisfaction >= 0.3 and stars >= 4:\n",
    "        return 'very_satisfied'\n",
    "    elif adjusted_satisfaction >= 0.0 and stars >= 3:\n",
    "        return 'satisfied'\n",
    "    elif adjusted_satisfaction >= -0.3 and stars >= 2:\n",
    "        return 'neutral'\n",
    "    else:\n",
    "        return 'dissatisfied'\n",
    "\n",
    "# Generate time sensitivity classification labels\n",
    "def generate_time_sensitivity_labels(row):\n",
    "    \"\"\"Generate time sensitivity labels based on temporal response patterns\"\"\"\n",
    "    visit_time = row['visit_time']\n",
    "    stars = row['stars']\n",
    "    wait_time = row['wait_time_numeric']\n",
    "    \n",
    "    # Time sensitive if satisfaction drops significantly during peak times with wait\n",
    "    if visit_time in ['Public holiday', 'Weekend'] and wait_time >= 30 and stars <= 3:\n",
    "        return 'time_sensitive'\n",
    "    elif wait_time >= 45 and stars <= 2:\n",
    "        return 'time_sensitive'\n",
    "    else:\n",
    "        return 'time_tolerant'\n",
    "\n",
    "# Apply all label generation functions\n",
    "df_filtered['tolerance_label'] = df_filtered.apply(generate_tolerance_labels_advanced, axis=1)\n",
    "df_filtered['wait_threshold'] = df_filtered.apply(generate_wait_threshold_labels, axis=1)\n",
    "df_filtered['wait_satisfaction'] = df_filtered.apply(generate_wait_experience_satisfaction, axis=1)\n",
    "df_filtered['time_sensitivity'] = df_filtered.apply(generate_time_sensitivity_labels, axis=1)\n",
    "\n",
    "print(\"All labels generated successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Rides Ranking Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rides ranking analysis completed: 17 rides\n"
     ]
    }
   ],
   "source": [
    "# Generate rides-specific tolerance ranking data\n",
    "def extract_rides_ranking_data(df_filtered):\n",
    "    \"\"\"Extract rides tolerance ranking analysis\"\"\"\n",
    "    rides_data = []\n",
    "    \n",
    "    for _, row in df_filtered.iterrows():\n",
    "        try:\n",
    "            rides = eval(row['label_rides']) if pd.notna(row['label_rides']) else []\n",
    "            if rides:\n",
    "                for ride in rides:\n",
    "                    rides_data.append({\n",
    "                        'ride_name': ride,\n",
    "                        'stars': row['stars'],\n",
    "                        'wait_time_numeric': row['wait_time_numeric'],\n",
    "                        'tolerance_label': row['tolerance_label'],\n",
    "                        'wait_threshold': row['wait_threshold'],\n",
    "                        'visit_time': row['visit_time'],\n",
    "                        'thrill_level': facility_thrill_scores.get(ride, 0),\n",
    "                        'review_sentiment': analyzer.polarity_scores(row['review'])['compound']\n",
    "                    })\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    rides_df = pd.DataFrame(rides_data)\n",
    "    \n",
    "    if len(rides_df) > 0:\n",
    "        # Calculate aggregated tolerance metrics per ride\n",
    "        rides_ranking = rides_df.groupby('ride_name').agg({\n",
    "            'stars': 'mean',\n",
    "            'wait_time_numeric': 'mean',\n",
    "            'wait_threshold': 'mean',\n",
    "            'tolerance_label': lambda x: (x == 'high_tolerance').mean(),\n",
    "            'thrill_level': 'first',\n",
    "            'review_sentiment': 'mean'\n",
    "        }).round(3)\n",
    "        \n",
    "        rides_ranking.columns = ['avg_stars', 'avg_wait_time', 'avg_threshold', \n",
    "                                'tolerance_rate', 'thrill_level', 'avg_sentiment']\n",
    "        \n",
    "        # Calculate composite tolerance score\n",
    "        rides_ranking['tolerance_score'] = (\n",
    "            rides_ranking['tolerance_rate'] * 0.4 + \n",
    "            (rides_ranking['avg_stars'] / 5) * 0.3 + \n",
    "            ((rides_ranking['avg_sentiment'] + 1) / 2) * 0.3\n",
    "        )\n",
    "        \n",
    "        return rides_ranking.sort_values('tolerance_score', ascending=False)\n",
    "    else:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "rides_ranking = extract_rides_ranking_data(df_filtered)\n",
    "print(f\"Rides ranking analysis completed: {len(rides_ranking)} rides\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Data Export & Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final dataset shape: (5409, 43)\n",
      "Feature dimensions: 32D\n",
      "Tolerance labels: {'high_tolerance': np.int64(4006), 'critical_tolerance': np.int64(745), 'tolerance_collapse': np.int64(658)}\n",
      "Wait satisfaction: {'very_satisfied': np.int64(3511), 'dissatisfied': np.int64(764), 'satisfied': np.int64(684), 'neutral': np.int64(450)}\n",
      "Time sensitivity: {'time_tolerant': np.int64(4987), 'time_sensitive': np.int64(422)}\n",
      "\n",
      "Data export completed successfully\n"
     ]
    }
   ],
   "source": [
    "# Combine all features into final dataset\n",
    "all_features = pd.concat([\n",
    "    sentiment_df,\n",
    "    temporal_df,\n",
    "    facility_df,\n",
    "    user_df,\n",
    "    time_sensitivity_df\n",
    "], axis=1)\n",
    "\n",
    "# Create final dataset with metadata and labels\n",
    "final_dataset = pd.concat([\n",
    "    df_filtered[['review_index', 'stars', 'name', 'review', 'publishedAtDate', \n",
    "                'visit_time', 'wait_time', 'tolerance_label', 'wait_threshold', \n",
    "                'wait_satisfaction', 'time_sensitivity']].reset_index(drop=True),\n",
    "    all_features.reset_index(drop=True)\n",
    "], axis=1)\n",
    "\n",
    "# Export datasets\n",
    "final_dataset.to_csv('data/processed/uss_features_labels.csv', index=False)\n",
    "if len(rides_ranking) > 0:\n",
    "    rides_ranking.to_csv('data/processed/rides_ranking_analysis.csv')\n",
    "\n",
    "# Display summary statistics\n",
    "print(f\"Final dataset shape: {final_dataset.shape}\")\n",
    "print(f\"Feature dimensions: {all_features.shape[1]}D\")\n",
    "print(f\"Tolerance labels: {dict(final_dataset['tolerance_label'].value_counts())}\")\n",
    "print(f\"Wait satisfaction: {dict(final_dataset['wait_satisfaction'].value_counts())}\")\n",
    "print(f\"Time sensitivity: {dict(final_dataset['time_sensitivity'].value_counts())}\")\n",
    "print(\"\\nData export completed successfully\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3_12_8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
